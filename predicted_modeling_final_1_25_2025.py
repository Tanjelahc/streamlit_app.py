# -*- coding: utf-8 -*-
"""predicted modeling- Final: 1/25/2025

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LXpSUAJHYzMzMSZxI_kmwcci81Cb8kpu
"""

# Install necessary libraries (uncomment if needed)
# !pip install requests pandas numpy matplotlib

# Import libraries
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time

def fetch_stock_data(symbol, api_key):
    """
    Fetch daily stock data using the Marketstack API.
    Args:
        symbol (str): Stock symbol (e.g., 'AAPL').
        api_key (str): Marketstack API key.
    Returns:
        pd.DataFrame: Dataframe containing stock data.
    """
    # Define dynamic time range: past year
    current_time = pd.Timestamp.now()
    one_year_ago = current_time - pd.DateOffset(years=1)

    url = f"http://api.marketstack.com/v1/eod?access_key={api_key}&symbols={symbol}&date_from={one_year_ago.date()}&date_to={current_time.date()}"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        if "data" in data and len(data["data"]) > 0:
            df = pd.DataFrame(data["data"])
            df["Date"] = pd.to_datetime(df["date"])
            df = df.rename(columns={
                "open": "Open",
                "high": "High",
                "low": "Low",
                "close": "Close",
                "volume": "Volume"
            })
            df = df[["Date", "Open", "High", "Low", "Close", "Volume"]]
            df.set_index("Date", inplace=True)
            df.sort_index(inplace=True)
            return df
        else:
            print("Error in API response: No data available.")
    else:
        print(f"HTTP Error {response.status_code}: {response.text}")
    return None

def calculate_technical_indicators(df):
    """
    Add technical indicators to the stock data.
    Args:
        df (pd.DataFrame): Dataframe containing stock data.
    Returns:
        pd.DataFrame: Dataframe with added technical indicators.
    """
    # Simple Moving Average (SMA)
    df["SMA_20"] = df["Close"].rolling(window=20).mean()

    # Exponential Moving Average (EMA)
    df["EMA_20"] = df["Close"].ewm(span=20, adjust=False).mean()

    # Relative Strength Index (RSI)
    delta = df["Close"].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df["RSI"] = 100 - (100 / (1 + rs))

    # Bollinger Bands
    df["BB_Middle"] = df["Close"].rolling(window=20).mean()
    df["BB_Upper"] = df["BB_Middle"] + (df["Close"].rolling(window=20).std() * 2)
    df["BB_Lower"] = df["BB_Middle"] - (df["Close"].rolling(window=20).std() * 2)

    # Moving Average Convergence Divergence (MACD)
    ema_12 = df["Close"].ewm(span=12, adjust=False).mean()
    ema_26 = df["Close"].ewm(span=26, adjust=False).mean()
    df["MACD"] = ema_12 - ema_26
    df["Signal_Line"] = df["MACD"].ewm(span=9, adjust=False).mean()

    # Lagged Features
    df["Lagged_Close_1"] = df["Close"].shift(1)
    df["Lagged_Close_2"] = df["Close"].shift(2)

    return df.dropna()

def visualize_stock_data(df, stock_symbol):
    """
    Create visualizations for the stock data and technical indicators.
    Args:
        df (pd.DataFrame): Dataframe containing stock data and indicators.
        stock_symbol (str): Stock symbol.
    """
    plt.figure(figsize=(15, 8))

    # Plot Closing Price with SMA and EMA
    plt.subplot(2, 2, 1)
    plt.plot(df.index, df["Close"], label="Closing Price", color="blue")
    plt.plot(df.index, df["SMA_20"], label="20-Day SMA", color="orange")
    plt.plot(df.index, df["EMA_20"], label="20-Day EMA", color="green")
    plt.title(f"{stock_symbol} - Closing Price with SMA and EMA")
    plt.xlabel("Date")
    plt.ylabel("Price ($)")
    plt.legend()

    # Plot RSI
    plt.subplot(2, 2, 2)
    plt.plot(df.index, df["RSI"], label="RSI", color="purple")
    plt.axhline(70, color="red", linestyle="--", label="Overbought")
    plt.axhline(30, color="green", linestyle="--", label="Oversold")
    plt.title(f"{stock_symbol} - Relative Strength Index (RSI)")
    plt.xlabel("Date")
    plt.ylabel("RSI")
    plt.legend()

    # Plot Bollinger Bands
    plt.subplot(2, 2, 3)
    plt.plot(df.index, df["Close"], label="Closing Price", color="blue")
    plt.plot(df.index, df["BB_Middle"], label="Middle Band", color="orange")
    plt.plot(df.index, df["BB_Upper"], label="Upper Band", color="green")
    plt.plot(df.index, df["BB_Lower"], label="Lower Band", color="red")
    plt.title(f"{stock_symbol} - Bollinger Bands")
    plt.xlabel("Date")
    plt.ylabel("Price ($)")
    plt.legend()

    # Plot MACD
    plt.subplot(2, 2, 4)
    plt.plot(df.index, df["MACD"], label="MACD", color="blue")
    plt.plot(df.index, df["Signal_Line"], label="Signal Line", color="orange")
    plt.title(f"{stock_symbol} - MACD")
    plt.xlabel("Date")
    plt.ylabel("MACD")
    plt.legend()

    plt.tight_layout()
    plt.show()

# Replace with your Marketstack API key
api_key = "9637122595cfe95b46234169ce0d7bcd"
stock_symbol = input("Enter Stock Symbol (e.g., AAPL): ")

# Fetch stock data
stock_data = fetch_stock_data(stock_symbol, api_key)
if stock_data is not None:
    print("Stock data fetched successfully!")
    stock_data = calculate_technical_indicators(stock_data)
    print(stock_data.head())

    # Save to CSV
    stock_data.to_csv("enhanced_stock_data.csv")
    print("Enhanced stock data saved to 'enhanced_stock_data.csv'.")

    # Visualize data
    visualize_stock_data(stock_data, stock_symbol)
else:
    print("Failed to fetch stock data. Please check the stock symbol and API key.")

from google.colab import drive
drive.mount('/content/drive')

# Install necessary libraries (uncomment if needed)
# !pip install matplotlib pandas numpy scikit-learn

# Import libraries
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Fetch stock price data using Alpha Vantage API
def fetch_stock_data(symbol, api_key):
    url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        if "Time Series (Daily)" in data:
            time_series = data["Time Series (Daily)"]
            df = pd.DataFrame.from_dict(time_series, orient="index")
            df = df.rename(columns={
                "1. open": "Open",
                "2. high": "High",
                "3. low": "Low",
                "4. close": "Close",
                "5. volume": "Volume"
            })
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()  # Ensure the data is sorted by date
            df = df.astype(float)  # Convert columns to numeric
            return df
    return None

# Replace with your Alpha Vantage API key
api_key = "UM2WCCP4BJIX6C0L"
stock_symbol = input("Enter Stock Symbol: ")  # Replace with the desired stock symbol
stock_data = fetch_stock_data(stock_symbol, api_key)

if stock_data is not None:
    print("Stock data fetched successfully!")
    # Display the first few rows of the data
    print(stock_data.head())
else:
    print("Failed to fetch stock data.")

# Visualize historical stock prices
plt.figure(figsize=(12, 6))
plt.plot(stock_data.index, stock_data["Close"], label="Closing Price", color="blue")
plt.title(f"{stock_symbol} Stock Price History")
plt.xlabel("Date")
plt.ylabel("Price ($)")
plt.legend()
plt.show()

# Prepare data for predictive modeling
stock_data["Future_Close"] = stock_data["Close"].shift(-1)  # Predict the next day's close
stock_data = stock_data.dropna()

# Define features (X) and target (y)
X = stock_data[["Open", "High", "Low", "Volume"]]
y = stock_data["Future_Close"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a predictive model (Random Forest Regressor)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"R^2 Score: {r2:.2f}")

# Visualize Actual vs. Predicted Prices
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label="Actual Prices", color="blue", alpha=0.7)
plt.plot(y_pred, label="Predicted Prices", color="red", alpha=0.7)
plt.title(f"{stock_symbol} - Actual vs Predicted Prices")
plt.xlabel("Test Sample Index")
plt.ylabel("Price ($)")
plt.legend()
plt.show()

from sklearn.ensemble import RandomForestRegressor
import numpy as np

# Calculate the daily percentage change in stock price
stock_data['Daily_Return'] = stock_data['Close'].pct_change() * 100  # Percentage change

# Drop any NaN values (due to pct_change)
stock_data = stock_data.dropna()

# Define the number of lag days (e.g., using the past 5 days to predict the next day's return)
n_lag = 5

# Create lag features (previous n days' returns)
for i in range(1, n_lag + 1):
    stock_data[f"lag_{i}"] = stock_data['Daily_Return'].shift(i)

# Drop rows with NaN values after creating lag features
stock_data = stock_data.dropna()

# Prepare the data for prediction (features: lagged returns, target: next day's return)
X = stock_data[[f"lag_{i}" for i in range(1, n_lag + 1)]]  # Lag features
y = stock_data['Daily_Return']  # Daily return as target

# Split the data into training and testing sets (train on the past data)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Regressor
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict the next 30 days' returns using the last available data
last_data = stock_data.tail(1)[[f"lag_{i}" for i in range(1, n_lag + 1)]].values  # Get the last row's lag features
predicted_returns = []

# Predict 30 days ahead
for _ in range(30):
    prediction = model.predict(last_data)[0]
    predicted_returns.append(prediction)

    # Update the last_data to include the new prediction for the next day's lag
    last_data = np.roll(last_data, shift=-1, axis=1)  # Shift the data
    last_data[0, -1] = prediction  # Add the new prediction as the latest lag feature

# Create a date range for the predicted future dates
future_dates = pd.date_range(start=stock_data.index[-1], periods=31, freq='D')[1:]

# Plot the historical returns and predicted returns for the next 30 days
plt.figure(figsize=(10, 6))

# Plot historical returns
plt.plot(stock_data.index, stock_data['Daily_Return'], label="Historical Daily Returns", color='blue')

# Plot predicted returns
plt.plot(future_dates, predicted_returns, label="Predicted Daily Returns (Next 30 Days)", color='red', linestyle='--')

# Title and labels
plt.title(f"Predicted Daily Returns for {stock_symbol} (Next 30 Days)")
plt.xlabel("Date")
plt.ylabel("Daily Return (%)")
plt.xticks(rotation=45)
plt.legend()

# Show grid and plot
plt.grid(True)
plt.show()

def calculate_var(stock_data, confidence_level=0.95):
    """
    Calculate Value at Risk (VaR) using the historical closing prices.
    Args:
        stock_data: DataFrame containing stock data with a 'Close' column.
        confidence_level: Confidence level for VaR calculation (default 0.95).
    Returns:
        VaR value at the specified confidence level.
    """
    # Calculate daily returns
    stock_data['Daily_Return'] = stock_data['Close'].pct_change()
    stock_data = stock_data.dropna()  # Drop NaN values resulting from the pct_change calculation

    # Calculate the quantile for the given confidence level
    var = np.percentile(stock_data['Daily_Return'], (1 - confidence_level) * 100)
    return var


# Add the risk analysis calculation after fetching and visualizing the stock data
if stock_data is not None:
    # Calculate VaR at 95% confidence level
    var_95 = calculate_var(stock_data, confidence_level=0.95)
    print(f"Value at Risk (95% Confidence Level): {var_95:.4f}")
    print("Explanation: At a 95% confidence level, there is a 5% chance that the stock price may decrease "
          f"by more than {var_95:.4%} over the next day based on historical data.")


    # Calculate VaR at 99% confidence level
    var_99 = calculate_var(stock_data, confidence_level=0.99)
    print(f"Value at Risk (99% Confidence Level): {var_99:.4f}")
    print("Explanation: At a 99% confidence level, there is a 1% chance that the stock price may decrease "
          f"by more than {var_99:.4%} over the next day based on historical data.")
else:
    print("Risk analysis could not be performed as stock data is unavailable.")

# Function to fetch and prepare stock data for multiple stocks
def fetch_and_prepare_stock_data(symbols, api_key):
    stock_data_dict = {}
    for symbol in symbols:
        print(f"Fetching data for {symbol}...")
        df = fetch_stock_data(symbol, api_key)
        if df is not None:
            df["Daily_Return"] = df["Close"].pct_change()
            df["Cumulative_Return"] = (1 + df["Daily_Return"]).cumprod()  # Cumulative return calculation
            df = df.dropna()
            stock_data_dict[symbol] = df
        else:
            print(f"Failed to fetch data for {symbol}.")
    return stock_data_dict


# Comparison Tool - Compare multiple stocks
def compare_stocks(stock_data_dict):
    # Plot closing prices
    plt.figure(figsize=(12, 6))
    for symbol, data in stock_data_dict.items():
        plt.plot(data.index, data["Close"], label=f"{symbol} Closing Price")
    plt.title("Comparison of Stock Closing Prices")
    plt.xlabel("Date")
    plt.ylabel("Price ($)")
    plt.legend()
    plt.show()


    # Plot cumulative returns
    plt.figure(figsize=(12, 6))
    for symbol, data in stock_data_dict.items():
        plt.plot(data.index, data["Cumulative_Return"], label=f"{symbol} Cumulative Return")
    plt.title("Comparison of Cumulative Returns")
    plt.xlabel("Date")
    plt.ylabel("Cumulative Return (Multiples of Initial Investment)")
    plt.legend()
    plt.show()


    print("\n--- Stock Performance Metrics ---")
    for symbol, data in stock_data_dict.items():
        avg_return = data["Daily_Return"].mean()
        risk = data["Daily_Return"].std()
        cumulative_return = data["Cumulative_Return"].iloc[-1] - 1
        print(f"{symbol}:")
        print(f"  - Average Daily Return: {avg_return:.4%}")
        print(f"  - Risk (Standard Deviation of Returns): {risk:.4%}")
        print(f"  - Cumulative Return: {cumulative_return:.4%}")
        print()


    # Correlation analysis
    print("\n--- Correlation Analysis ---")
    returns_df = pd.DataFrame({symbol: data["Daily_Return"] for symbol, data in stock_data_dict.items()})
    correlation_matrix = returns_df.corr()
    print(correlation_matrix)


    # Heatmap for correlation matrix
    try:
        import seaborn as sns
        plt.figure(figsize=(8, 6))
        sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
        plt.title("Correlation Matrix of Daily Returns")
        plt.show()
    except ImportError:
        print("Seaborn is not installed. Correlation heatmap could not be displayed.")


# Input for multiple stock symbols
stock_symbols = input("Enter stock symbols separated by commas: ").split(",")
stock_symbols = [symbol.strip().upper() for symbol in stock_symbols]  # Clean input


# Fetch and prepare data for all specified stocks
stock_data_dict = fetch_and_prepare_stock_data(stock_symbols, api_key)


# If data for multiple stocks is successfully fetched, compare them
if stock_data_dict:
    compare_stocks(stock_data_dict)
else:
    print("No valid stock data available for comparison.")

# Import libraries
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score






# Fetch stock price data using Alpha Vantage API
def fetch_stock_data(symbol, api_key):
    url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        if "Time Series (Daily)" in data:
            time_series = data["Time Series (Daily)"]
            df = pd.DataFrame.from_dict(time_series, orient="index")
            df = df.rename(columns={
                "1. open": "Open",
                "2. high": "High",
                "3. low": "Low",
                "4. close": "Close",
                "5. volume": "Volume"
            })
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()  # Ensure the data is sorted by date
            df = df.astype(float)  # Convert columns to numeric
            return df
    return None


# Your News API key
api_key = "82d56ba76cc0496485f655a5cea35685"


# API endpoint for news about LPL Financial
url = f"https://newsapi.org/v2/everything?q=LPL+Financial&apiKey={api_key}"


response = requests.get(url)
news_data = response.json()


# Print out headlines
for article in news_data['articles']:
    print(article['title'], "-", article['source']['name'])


# Check if the request was successful
if response.status_code == 200:
    articles = []
    for article in news_data['articles']:
        title = article.get('title', '')  # Use .get() to safely access 'title' and avoid KeyError
        source = article['source']['name'] if 'source' in article else 'Unknown'

        # Categorize the article based on certain keywords in the title
        if "price target" in title.lower() or "stock" in title.lower():
            category = "Stock Price Updates"
        elif "earnings" in title.lower() or "quarterly" in title.lower():
            category = "Company Announcements"
        elif "analysts" in title.lower() or "ratings" in title.lower():
            category = "Market Analysis"
        else:
            category = "Other"


        articles.append({'Title': title, 'Source': source, 'Category': category})


    # Create a DataFrame from the collected articles
    df = pd.DataFrame(articles)


    # Display the first few rows of the DataFrame
    print(df.head())


    # Visualize the frequency of news sources
    source_counts = df['Source'].value_counts()


    # Visualize the categories of the articles
    category_counts = df['Category'].value_counts()


    # Plot source frequencies
    plt.figure(figsize=(10, 6))
    source_counts.plot(kind='bar', color='skyblue')
    plt.title('News Articles by Source')
    plt.xlabel('News Source')
    plt.ylabel('Number of Articles')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()


    # Plot category frequencies
    plt.figure(figsize=(10, 6))
    category_counts.plot(kind='bar', color='lightgreen')
    plt.title('News Articles by Category')
    plt.xlabel('Category')
    plt.ylabel('Number of Articles')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()


    # Show both plots
    plt.show()


    # Optionally, save the data to a CSV file for further analysis
    df.to_csv("LPL_Financial_News.csv", index=False)
else:
    print("Failed to retrieve news data.")